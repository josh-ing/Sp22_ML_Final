{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "11.3\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.version.cuda)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "\n",
    "def spec_add_spaces(t: str) -> str:\n",
    "    \"Add spaces around / and # in `t`. \\n\"\n",
    "    return re.sub(r\"([/#\\n])\", r\" \\1 \", t)\n",
    "\n",
    "def rm_useless_spaces(t: str) -> str:\n",
    "    \"Remove multiple spaces in `t`.\"\n",
    "    return re.sub(\" {2,}\", \" \", t)\n",
    "\n",
    "def replace_multi_newline(t: str) -> str:\n",
    "    return re.sub(r\"(\\n(\\s)*){2,}\", \"\\n\", t)\n",
    "\n",
    "def fix_html(x: str) -> str:\n",
    "    \"List of replacements from html strings in `x`.\"\n",
    "    re1 = re.compile(r\"  +\")\n",
    "    x = (\n",
    "        x.replace(\"#39;\", \"'\")\n",
    "        .replace(\"amp;\", \"&\")\n",
    "        .replace(\"#146;\", \"'\")\n",
    "        .replace(\"nbsp;\", \" \")\n",
    "        .replace(\"#36;\", \"$\")\n",
    "        .replace(\"\\\\n\", \"\\n\")\n",
    "        .replace(\"quot;\", \"'\")\n",
    "        .replace(\"<br />\", \"\\n\")\n",
    "        .replace('\\\\\"', '\"')\n",
    "        .replace(\" @.@ \", \".\")\n",
    "        .replace(\" @-@ \", \"-\")\n",
    "        .replace(\" @,@ \", \",\")\n",
    "        .replace(\"\\\\\", \" \\\\ \")\n",
    "    )\n",
    "    return re1.sub(\" \", html.unescape(x))\n",
    "\n",
    "def clean_text(input_text):\n",
    "    text = fix_html(input_text)\n",
    "    text = replace_multi_newline(text)\n",
    "    text = spec_add_spaces(text)\n",
    "    text = rm_useless_spaces(text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\joshu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download('punkt')\n",
    "df = pd.read_csv(\"KickstarterData.csv\")\n",
    "df = df.dropna(axis = 0)\n",
    "df[\"tokenized\"] = df[\"name\"].apply(lambda x: nltk.word_tokenize(clean_text(x.lower())))\n",
    "df = df[(df[\"state\"] == \"successful\") |(df[\"state\"] == \"failed\")]\n",
    "df[\"hit\"] = np.where(df[\"state\"] == \"successful\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133851, 17)\n",
      "(197611, 17)\n"
     ]
    }
   ],
   "source": [
    "print(df[df[\"hit\"] == 1].shape)\n",
    "print(df[df[\"hit\"] == 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "PADDING_VALUE = 0\n",
    "UNK_VALUE     = 1\n",
    "\n",
    "def split_train_val_test(df, props=[.8, .1, .1]):\n",
    "    assert round(sum(props), 2) == 1 and len(props) >= 2\n",
    "    train_df, test_df, val_df = None, None, None\n",
    "\n",
    "    first_partition = int(df.shape[0] * props[0])\n",
    "    second_partition = int(df.shape[0] * (props[0] + props[1]))\n",
    "\n",
    "    train_df = df.iloc[:first_partition,:]\n",
    "    val_df = df.iloc[first_partition:second_partition,:]\n",
    "    test_df = df.iloc[second_partition:,:]\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "def generate_vocab_map(df, cutoff=2):\n",
    "    vocab          = {\"\": PADDING_VALUE, \"UNK\": UNK_VALUE}\n",
    "    reversed_vocab = None\n",
    "\n",
    "    cnt = {}\n",
    "    for tokens in df[\"tokenized\"]:\n",
    "      for word in tokens:\n",
    "        if (word in cnt):\n",
    "          cnt[word] = cnt[word] + 1\n",
    "        else:\n",
    "          cnt[word] = 1\n",
    "\n",
    "    reversed_vocab = {}\n",
    "    reversed_vocab[PADDING_VALUE] = \"\"\n",
    "    reversed_vocab[UNK_VALUE] = \"UNK\"\n",
    "    int_ID = 2\n",
    "    for word in cnt:\n",
    "      if (cnt[word] > cutoff):\n",
    "        vocab[word] = int_ID\n",
    "        reversed_vocab[int_ID] = word\n",
    "        int_ID = int_ID + 1\n",
    "    \n",
    "    return vocab, reversed_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df                         = df.sample(frac=0.1)\n",
    "train_df, val_df, test_df  = split_train_val_test(df, props=[.8, .1, .1])\n",
    "train_vocab, reverse_vocab = generate_vocab_map(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class WordDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, vocab, df, max_length=50):\n",
    "        self.vocab = vocab\n",
    "        self.df = df\n",
    "        self.max_length = max_length\n",
    "\n",
    "        return\n",
    "    \n",
    "    # return the length of the dataframe instance variable\n",
    "    def __len__(self):      \n",
    "        df_len = self.df.shape[0]\n",
    "        return df_len\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        for i in range(len(self.df[\"tokenized\"][index])):\n",
    "          if not(self.df[\"tokenized\"][index][i] in self.vocab):\n",
    "            self.df[\"tokenized\"][index][i] = \"UNK\"\n",
    "\n",
    "        mapped = []\n",
    "        for word in self.df[\"tokenized\"][index]:\n",
    "          if(len(mapped) < self.max_length):\n",
    "            mapped.append(self.vocab[word])\n",
    "        tokenized_word_tensor = torch.LongTensor(mapped)\n",
    "        tokenized_word_tensor = tokenized_word_tensor.to(torch.device(device))\n",
    "\n",
    "        curr_label = self.df[\"hit\"][index]\n",
    "\n",
    "        return tokenized_word_tensor, curr_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "train_dataset = WordDataset(train_vocab, train_df)\n",
    "val_dataset   = WordDataset(train_vocab, val_df)\n",
    "test_dataset  = WordDataset(train_vocab, test_df)\n",
    " \n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "val_sampler   = RandomSampler(val_dataset)\n",
    "test_sampler  = RandomSampler(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch, padding_value=PADDING_VALUE):\n",
    "    padded_tokens, y_labels = None, None\n",
    "\n",
    "    ptlist = [] # padded_tokens list version\n",
    "    ylist = []\n",
    "    for tup in batch:\n",
    "      ptlist.append(tup[0])\n",
    "      ylist.append(tup[1])\n",
    "    padded_tokens = pad_sequence(ptlist, batch_first = True, padding_value = padding_value)\n",
    "    y_labels = torch.LongTensor(ylist)\n",
    "    \n",
    "    return padded_tokens, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
    "val_iterator   = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn)\n",
    "test_iterator  = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NBOW(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lin_sig = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding_layer(x)\n",
    "        mean_embed = torch.mean(embedded, axis = 1)\n",
    "        x_res = self.lin_sig(mean_embed)\n",
    "\n",
    "        return x_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NBOW(vocab_size = len(train_vocab.keys()), embedding_dim = 300).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "criterion = nn.BCELoss().to(torch.device(device))\n",
    "optimizer = Adam(model.parameters(), lr = 0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, criterion, optim, iterator):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(iterator):\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss = criterion(model.forward(x).reshape(y.shape), y.float().to(torch.device(device)))\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "def val_loop(model, iterator):\n",
    "    true, pred = [], []\n",
    "\n",
    "    for x, y in tqdm(iterator):\n",
    "      for tv in y:\n",
    "        if (tv == 0):\n",
    "          true.append(False)\n",
    "        elif (tv == 1):\n",
    "          true.append(True)\n",
    "      p = model.forward(x)\n",
    "      for pv in p:\n",
    "        if (pv <= 0.5):\n",
    "          pred.append(False)\n",
    "        else:\n",
    "          pred.append(True)\n",
    "\n",
    "    return true, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(true, pred):\n",
    "    acc = None\n",
    "\n",
    "    same = 0\n",
    "    for i in range(len(true)):\n",
    "      if(true[i] == pred[i]):\n",
    "        same += 1\n",
    "    acc = same / len(true)\n",
    "\n",
    "    return acc\n",
    "\n",
    "def binary_f1(true, pred, selected_class=True):\n",
    "    f1 = None\n",
    "\n",
    "    tp = 0 # True Positive\n",
    "    fp = 0 # False Positive. Actually negative, but predicted to positive\n",
    "    fn = 0 # False Negative. Actually positive, but predicted to negative\n",
    "    tn = 0 # True Negative.\n",
    "\n",
    "    for i in range(len(true)):\n",
    "      if(true[i] == True) and (pred[i] == True):\n",
    "        tp = tp + 1\n",
    "      elif(true[i] == True) and (pred[i] == False):\n",
    "        fn = fn + 1\n",
    "      elif(true[i] == False) and (pred[i] == True):\n",
    "        fp = fp + 1\n",
    "      elif(true[i] == False) and (pred[i] == False):\n",
    "        tn = tn + 1\n",
    "    \n",
    "    if(selected_class == True):\n",
    "      precision = tp / (tp + fp + 1)\n",
    "      recall = tp / (tp + fn + 1)\n",
    "    elif(selected_class == False):\n",
    "      precision = tn / (tn + fn + 1)\n",
    "      recall = tn / (tn + fp + 1)\n",
    "\n",
    "    f1 = 2 * (precision*recall) / (precision + recall + 1e-10) #prevent zerodivision\n",
    "\n",
    "    return f1\n",
    "\n",
    "def binary_macro_f1(true, pred):\n",
    "    averaged_macro_f1 = 0.5*(binary_f1(true, pred, selected_class=True) + binary_f1(true, pred, selected_class=False))\n",
    "    return averaged_macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_EPOCHS = 5\n",
    "for epoch in range(TOTAL_EPOCHS):\n",
    "    train_loss = train_loop(model, criterion, optimizer, train_iterator)\n",
    "    true, pred = val_loop(model, val_iterator)\n",
    "    print(f\"EPOCH: {epoch}\")\n",
    "    print(f\"TRAIN LOSS: {train_loss}\")\n",
    "    print(f\"VAL F-1: {binary_macro_f1(true, pred)}\")\n",
    "    print(f\"VAL ACC: {accuracy(true, pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"hit\"] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, \\\n",
    "                 num_layers=1, bidirectional=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = 0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers = num_layers, bidirectional = bidirectional)\n",
    "        self.lin_sig = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = torch.transpose(embedded, 0, 1)\n",
    "\n",
    "        outputs, (h, c) = self.lstm(embedded)\n",
    "\n",
    "        predictions = self.lin_sig(outputs)\n",
    "        predictions = torch.mean(predictions, axis = 0)\n",
    "        predictions = predictions.reshape((-1,))\n",
    "\n",
    "        return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
    "val_iterator   = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn)\n",
    "test_iterator  = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = RecurrentModel(vocab_size    = len(train_vocab.keys()),\n",
    "                            embedding_dim = 300,\n",
    "                            hidden_dim    = 300,\n",
    "                            num_layers    = 1,\n",
    "                            bidirectional = True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_criterion = nn.BCELoss().to(torch.device(device))\n",
    "lstm_optimizer = Adam(lstm_model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:51<00:00, 32.40it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 119.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "TRAIN LOSS: 1075.2413330078125\n",
      "VAL F-1: 0.5685804533164841\n",
      "VAL ACC: 0.6289592760180995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:50<00:00, 33.08it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 130.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "TRAIN LOSS: 976.503662109375\n",
      "VAL F-1: 0.5988481683637019\n",
      "VAL ACC: 0.633182503770739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:49<00:00, 33.30it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 139.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 2\n",
      "TRAIN LOSS: 832.355224609375\n",
      "VAL F-1: 0.6057402997552858\n",
      "VAL ACC: 0.6277526395173454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:49<00:00, 33.39it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 121.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 3\n",
      "TRAIN LOSS: 666.4716186523438\n",
      "VAL F-1: 0.5977074037468737\n",
      "VAL ACC: 0.6099547511312218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:51<00:00, 32.44it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 121.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 4\n",
      "TRAIN LOSS: 521.3535766601562\n",
      "VAL F-1: 0.5974350955285338\n",
      "VAL ACC: 0.6114630467571645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:50<00:00, 33.07it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 143.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 5\n",
      "TRAIN LOSS: 418.7719421386719\n",
      "VAL F-1: 0.5868491866356917\n",
      "VAL ACC: 0.5972850678733032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:51<00:00, 32.02it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 121.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 6\n",
      "TRAIN LOSS: 357.5799255371094\n",
      "VAL F-1: 0.5728016271098701\n",
      "VAL ACC: 0.6048265460030166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:53<00:00, 30.78it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 130.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 7\n",
      "TRAIN LOSS: 314.3688659667969\n",
      "VAL F-1: 0.581587697575056\n",
      "VAL ACC: 0.6009049773755656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:53<00:00, 30.83it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 117.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 8\n",
      "TRAIN LOSS: 288.42974853515625\n",
      "VAL F-1: 0.5786867302801472\n",
      "VAL ACC: 0.5957767722473605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:52<00:00, 31.47it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 119.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 9\n",
      "TRAIN LOSS: 265.5520324707031\n",
      "VAL F-1: 0.586384010212455\n",
      "VAL ACC: 0.6018099547511312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:52<00:00, 31.31it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 123.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 10\n",
      "TRAIN LOSS: 255.9941864013672\n",
      "VAL F-1: 0.5796682366273573\n",
      "VAL ACC: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:52<00:00, 31.56it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 141.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 11\n",
      "TRAIN LOSS: 257.0727844238281\n",
      "VAL F-1: 0.5819396621899497\n",
      "VAL ACC: 0.6036199095022624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:52<00:00, 31.76it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 123.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 12\n",
      "TRAIN LOSS: 241.17816162109375\n",
      "VAL F-1: 0.5862484407415689\n",
      "VAL ACC: 0.6012066365007541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:55<00:00, 29.69it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 111.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 13\n",
      "TRAIN LOSS: 227.02317810058594\n",
      "VAL F-1: 0.5720056903023583\n",
      "VAL ACC: 0.5936651583710407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [01:00<00:00, 27.58it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 115.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 14\n",
      "TRAIN LOSS: 221.8616180419922\n",
      "VAL F-1: 0.5745527440773631\n",
      "VAL ACC: 0.5906485671191554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:58<00:00, 28.44it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 121.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 15\n",
      "TRAIN LOSS: 211.6234893798828\n",
      "VAL F-1: 0.56920703776859\n",
      "VAL ACC: 0.5879336349924585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:58<00:00, 28.32it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 127.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 16\n",
      "TRAIN LOSS: 215.39613342285156\n",
      "VAL F-1: 0.5759328044620415\n",
      "VAL ACC: 0.5972850678733032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:51<00:00, 31.91it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 130.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 17\n",
      "TRAIN LOSS: 215.46658325195312\n",
      "VAL F-1: 0.5779911712567093\n",
      "VAL ACC: 0.604524886877828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:53<00:00, 31.19it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 132.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 18\n",
      "TRAIN LOSS: 215.99246215820312\n",
      "VAL F-1: 0.5772015170887824\n",
      "VAL ACC: 0.5984917043740573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:51<00:00, 31.96it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 128.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 19\n",
      "TRAIN LOSS: 199.5985565185547\n",
      "VAL F-1: 0.5750960335683564\n",
      "VAL ACC: 0.5954751131221719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:51<00:00, 31.96it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 119.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 20\n",
      "TRAIN LOSS: 195.6132049560547\n",
      "VAL F-1: 0.5693557363398061\n",
      "VAL ACC: 0.5894419306184012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:56<00:00, 29.14it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 117.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 21\n",
      "TRAIN LOSS: 198.49472045898438\n",
      "VAL F-1: 0.5733782440353609\n",
      "VAL ACC: 0.5945701357466063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:56<00:00, 29.33it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 114.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 22\n",
      "TRAIN LOSS: 194.08448791503906\n",
      "VAL F-1: 0.5818403861841323\n",
      "VAL ACC: 0.5972850678733032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:59<00:00, 27.80it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 133.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 23\n",
      "TRAIN LOSS: 187.73678588867188\n",
      "VAL F-1: 0.5688199035580682\n",
      "VAL ACC: 0.5903469079939668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:57<00:00, 28.64it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 138.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 24\n",
      "TRAIN LOSS: 195.3265838623047\n",
      "VAL F-1: 0.5720520872071158\n",
      "VAL ACC: 0.5963800904977375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:59<00:00, 27.99it/s]\n",
      "100%|██████████| 208/208 [00:02<00:00, 103.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 25\n",
      "TRAIN LOSS: 195.0481719970703\n",
      "VAL F-1: 0.5668003036706871\n",
      "VAL ACC: 0.5855203619909503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:56<00:00, 29.15it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 119.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 26\n",
      "TRAIN LOSS: 187.36607360839844\n",
      "VAL F-1: 0.5771021584576231\n",
      "VAL ACC: 0.5918552036199095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:57<00:00, 28.66it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 146.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 27\n",
      "TRAIN LOSS: 191.87303161621094\n",
      "VAL F-1: 0.5709987912864878\n",
      "VAL ACC: 0.5882352941176471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:56<00:00, 29.60it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 123.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 28\n",
      "TRAIN LOSS: 189.7032470703125\n",
      "VAL F-1: 0.577902980452983\n",
      "VAL ACC: 0.5948717948717949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:55<00:00, 29.71it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 116.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 29\n",
      "TRAIN LOSS: 189.91241455078125\n",
      "VAL F-1: 0.5795798108769729\n",
      "VAL ACC: 0.5990950226244344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_plot = []\n",
    "TOTAL_EPOCHS = 30\n",
    "for epoch in range(TOTAL_EPOCHS):\n",
    "    train_loss = train_loop(lstm_model, lstm_criterion, lstm_optimizer, train_iterator)\n",
    "    true, pred = val_loop(lstm_model, val_iterator)\n",
    "    accuracy_plot.append(accuracy(true, pred))\n",
    "    print(f\"EPOCH: {epoch}\")\n",
    "    print(f\"TRAIN LOSS: {train_loss}\")\n",
    "    print(f\"VAL F-1: {binary_macro_f1(true, pred)}\")\n",
    "    print(f\"VAL ACC: {accuracy(true, pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208/208 [00:01<00:00, 133.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST F-1: 0.5636440025044578\n",
      "TEST ACC: 0.5864253393665159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true, pred = val_loop(lstm_model, test_iterator)\n",
    "print()\n",
    "print(f\"TEST F-1: {binary_macro_f1(true, pred)}\")\n",
    "print(f\"TEST ACC: {accuracy(true, pred)}\")\n",
    "epochs = [range(0, TOTAL_EPOCHS)]\n",
    "fig = plt.figure()\n",
    "plt.title('LSTM Accuracy')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.scatter(epochs, accuracy_plot, color = 'blue')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ddb23e51bf74c8e92c2ac4257bae0601254c9c7d972fd7c7abd355ea851f229"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
