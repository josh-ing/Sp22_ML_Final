{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b58471bb",
   "metadata": {},
   "source": [
    "Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "334428e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc14d26",
   "metadata": {},
   "source": [
    "Naive Bayes Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c0b1b20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Load test file\n",
    "        csv_file = open('KickStarterData.csv', encoding=\"utf-8\")\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        \n",
    "        data_arr = np.empty((10, 15), dtype=object)\n",
    "        counter = 0\n",
    "        for row in csv_reader:\n",
    "            if (counter < 10):\n",
    "                temp_arr = np.array(row)\n",
    "                data_arr[counter] = temp_arr\n",
    "                counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "650bad05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be16b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cleaning(object):\n",
    "    #class to handle cleaning data (standardizing features, dimensionality reduction, etc.)\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.U = None\n",
    "        self.V = None\n",
    "        self.S = None\n",
    "\n",
    "    #PCA for dimensionality reduction of the dataset\n",
    "    def pca(self, X, var = False, k=2):\n",
    "        \"\"\"\n",
    "        ARGS:\n",
    "            X: (N X D) data set as a numpy array, uncentered\n",
    "            var: whether to use retained variance or number of features as the basis of reduction\n",
    "            k: if var=FALSE, k is the number of features to be kept. if var=TRUE, k is the retained variance as a decimal\n",
    "\n",
    "        RETURNS:\n",
    "            new_data: dataset (as a numpy array) obtained by applying PCA on the original dataset\n",
    "\n",
    "        SETS:\n",
    "            self.U: (N, min(N,D))\n",
    "            self.V: (min(N,D), D)\n",
    "            self.S: (min(N,D), ) \n",
    "        \"\"\"\n",
    "\n",
    "        #center the data set\n",
    "        centeredData = X - np.mean(X, axis=0)\n",
    "        self.U, self.S, self.V = np.linalg.svd(centeredData, full_matrices = False)\n",
    "\n",
    "        #if var== False, do PCA based on the specified number of features\n",
    "        if (var == False):\n",
    "            #if k not entered correctly (less than one feature entered), assume default number of features\n",
    "            if (k < 1):\n",
    "                k = 2\n",
    "            self.U = self.U[:,0:k]\n",
    "            self.S = self.S[0:k]\n",
    "            self.V = self.V[0:k,:]\n",
    "            new_data = np.matmul(centeredData, (self.V).T)\n",
    "        \n",
    "        #if var==True, do PCA based on the specified number of features\n",
    "        else:\n",
    "            #if k not entered correctly (greater than 100%), assume default variance\n",
    "            if (k >= 1):\n",
    "                k = .99\n",
    "            new_data = np.matmul(centeredData, (self.V).T)\n",
    "            origVar = np.sum(np.square(self.S))\n",
    "            ssquared = np.square(self.S)\n",
    "            for i in range(np.shape(centeredData)[1]):\n",
    "                var = np.sum(ssquared[0:i])/origVar\n",
    "                if (var >= k):\n",
    "                    self.S = self.S[0:i]\n",
    "                    self.U = self.U[:,0:i]\n",
    "                    self.V = self.V[0:i,:]\n",
    "                    new_data= np.matmul(centeredData, (self.V).T)\n",
    "        \n",
    "        return new_data\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
