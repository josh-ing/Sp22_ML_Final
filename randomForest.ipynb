{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class randomForest(object):\n",
    "    def __init__(self, n_estimators, max_depth, max_features, random_seed=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.random_seed = random_seed\n",
    "        self.row_indices = []\n",
    "        self.feature_indices = []\n",
    "        self.out_of_bag = []\n",
    "        self.decision_trees = [sklearn.tree.DecisionTreeClassifier(max_depth=None, criterion='entropy') for i in range(n_estimators)]\n",
    "\n",
    "    def bootstrap(self, num_training, num_features, random_seed = None):\n",
    "        np.random.seed(seed = self.random_seed)\n",
    "        for i in range(self.n_estimators):\n",
    "            total = set(list(range(num_training)))\n",
    "            row_indices, col_indices = np.random.choice(num_training, num_training), np.random.choice(num_features, int(num_features * self.max_features), replace=False)\n",
    "            total = total - set(row_indices)\n",
    "            self.row_indices.append(row_indices)\n",
    "            self.feature_indices.append(col_indices)\n",
    "            self.out_of_bag.append(total)\n",
    "    \n",
    "    def fit_rforest(self, x, y):\n",
    "        self.bootstrap(np.shape(x)[0], np.shape(x)[1])\n",
    "        for i in range(self.n_estimators):\n",
    "            bsX = x[self.row_indices[i]][:,self.feature_indices[i]]\n",
    "            bsY = y[self.row_indices[i]]\n",
    "            self.decision_trees[i].fit(bsX, bsY)\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        accuracy = []\n",
    "        for i in range(len(X)):\n",
    "            predictions = []\n",
    "            for j in range(self.n_estimators):\n",
    "                if i in self.out_of_bag[j]:\n",
    "                    predictions.append(self.decision_trees[j].predict(np.reshape(X[i][self.feature_indices[j]], (1,-1)))[0])\n",
    "            if len(predictions) > 0:\n",
    "                accuracy.append(np.sum(predictions == y[i]) / float(len(predictions)))\n",
    "        return np.mean(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "csv_file = open('KickStarterData_nb.csv', encoding=\"utf-8\")\n",
    "csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "csv_list = list(csv_reader)\n",
    "#remove one for the feature titles\n",
    "totalN = len(csv_list) - 1\n",
    "#remove 2 for the id and the y column\n",
    "D = len(csv_list[1]) - 2\n",
    "\n",
    "#remove the feature titles\n",
    "csv_list.pop(0)\n",
    "#split into x and y, remove id\n",
    "nparray = np.array(csv_list)\n",
    "\n",
    "#shape of X: (331675, 6)\n",
    "X = nparray[0:totalN,1:]\n",
    "#shape of y: (331675,)\n",
    "y = nparray[:, D+1]\n",
    "\n",
    "\n",
    "#split into training and testing data\n",
    "train = int(totalN*0.1)\n",
    "Xtrain = X[:train]\n",
    "ytrain = y[:train]\n",
    "\n",
    "Xtest = X[train+1:]\n",
    "ytest = y[train+1:]\n",
    "\n",
    "\n",
    "random_forest = sklearn.ensemble.RandomForestClassifier(bootstrap=True)\n",
    "random_forest.fit(Xtrain, ytrain)\n",
    "ypredicted = random_forest.predict(Xtest)\n",
    "\n",
    "accuracy = sklearn.metrics.accuracy_score(ytest,ypredicted)\n",
    "print(accuracy)\n",
    "\n",
    "totalCorrect = 0\n",
    "for i in range(np.shape(ytest)[0]):\n",
    "    if ytest[i] == ypredicted[i]:\n",
    "        totalCorrect += 1\n",
    "\n",
    "print(totalCorrect/np.shape(ytest)[0])\n",
    "\n",
    "class_names = decision_tree_classifier.classes_\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=800)\n",
    "sklearn.tree.plot_tree(random_forest.estimators_[0],\n",
    "               feature_names = random_forest.feature_importance, \n",
    "               class_names=cn,\n",
    "               filled = True);\n",
    "fig.savefig('rf_individualtree.png')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43a82382831d5fba1f3416ee2444681233383515fca786e8121660ccddea97a9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ml_hw4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
